# -*- coding: utf-8 -*-
"""Sentiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wbL7FfyPZHlFAtJz1KVmGjpvkAQh9-KV
"""

# from google.colab import drive
# drive.mount('/content/drive')

# !pip install bnltk

from sklearn.model_selection import train_test_split
from bnltk.tokenize import Tokenizers
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import make_scorer, roc_auc_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
import matplotlib.pyplot as plt
import sklearn.metrics as metrics
import numpy as np
import collections
import nltk
import pandas as pd
import codecs

INPUT_FILE ="/content/ecommerce_dataset.txt"
stopwords_list = "/content/stopwords.txt"
import string
counter = collections.Counter()
tokenizer = Tokenizers()
maxlen =0
xs, ys = [], []
bangla_stopwords = codecs.open(stopwords_list,'r',encoding='utf-8').read().split()

fin = codecs.open(INPUT_FILE,'r',encoding='utf-16')
punctuation_marks = set(string.punctuation)
for line in fin:
  _, sent=line.strip().split("\t")
  print("Lable:",_)
  print("Sentence: ",sent)

  #tokenization
  words = tokenizer.bn_word_tokenizer(sent)
  print("After Tokenizing: ",words)

  #Exclude punctuation marks
  wordsExcludingPunctuation = [word for word in words if word not in punctuation_marks]
  print("After excluding puntuation: ",wordsExcludingPunctuation)

  #Exclude Stopwords
  wordsExcludingStopwords = [word for word in wordsExcludingPunctuation if word not in bangla_stopwords]
  print("After Excluding Stopwords: ", wordsExcludingStopwords)
  if len(wordsExcludingPunctuation)>maxlen:
    maxlen = len(wordsExcludingPunctuation)

  #update word frequency counter
  for word in wordsExcludingStopwords:
      counter[word] += 1


  print("***************************************************************************************")


  ys.append(int(_))
  xs.append(' '.join(wordsExcludingStopwords))

fin.close()

#train and test data creation from main dataset
Xtrain, Xtest, Ytrain, Ytest = train_test_split(xs, ys, test_size=0.25, random_state = 0)
Xtrain

#feature extraction....
#TFIDF vecto
#Xtrain.....>>>> Xtrain_tf (Vectorize)

tfidf = TfidfVectorizer(ngram_range=(1,3),use_idf=True,tokenizer= lambda x:x.split())

Xtrain_tf = tfidf.fit_transform(Xtrain)
print("n_sample: %d, n_features: %d" % Xtrain_tf.shape)

Xtest_tf = tfidf.transform(Xtest)
print("n_sample: %d, n_features: %d" % Xtest_tf.shape)

"""Logistic regression"""

from sklearn.linear_model import LogisticRegression
LRClassification = LogisticRegression()
LRClassification.fit(Xtrain_tf, Ytrain)
y_pred = LRClassification.predict(Xtest_tf)
print(confusion_matrix(Ytest,y_pred))
print(classification_report(Ytest,y_pred))
cm= confusion_matrix(Ytest,y_pred)

#create a confusion Matrix Display object
matrix = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])

#plot the confusion matrix with color map
matrix.plot(cmap=plt.cm.Reds)

#costomize the plot
matrix.ax_.set_title('Confusion Matrix Plot for Logistic Regression Classifier{L2}', color='black')
plt.xlabel('Predicted label', color='black')
plt.ylabel('True label', color='black')
plt.gcf().axes[0].tick_params(color='black')
plt.gcf().axes[1].tick_params(color='black')
plt.gcf().set_size_inches(10,6)

#show the plot
plt.show()

fprLR, tprLR, thesholdsLR = metrics.roc_curve(Ytest, y_pred)

from sklearn.linear_model import LogisticRegression
LRClassification2 = LogisticRegression(penalty='l1', solver='liblinear')
LRClassification2.fit(Xtrain_tf, Ytrain)
y_pred2 = LRClassification2.predict(Xtest_tf)
print(confusion_matrix(Ytest,y_pred2))
print(classification_report(Ytest,y_pred2))
cm = confusion_matrix(Ytest,y_pred2)

matrix = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])

matrix.plot(cmap=plt.cm.Reds)

matrix.ax_.set_title('confusion Matrix Plot for Logistic Regression Classifier{L1}', color='black')
plt.xlabel('Predicted label', color='black')
plt.ylabel('True label', color='black')
plt.gcf().axes[0].tick_params(color='black')
plt.gcf().axes[1].tick_params(color='black')
plt.gcf().set_size_inches(10,6)

plt.show()

fprLR2, tprLR2, thesholdsLR2 = metrics.roc_curve(Ytest, y_pred2)

"""SVM"""

from sklearn import svm
clf = svm.SVC(kernel='linear')
clf.fit(Xtrain_tf, Ytrain)
y_pred3 = clf.predict(Xtest_tf)
print(confusion_matrix(Ytest,y_pred3))
print(classification_report(Ytest,y_pred3))
cm = confusion_matrix(Ytest,y_pred3)

matrix = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])

matrix.plot(cmap=plt.cm.Reds)

matrix.ax_.set_title('confusion Matrix Plot for Logistic Regression Classifier{L1}', color='black')
plt.xlabel('Predicted label', color='black')
plt.ylabel('True label', color='black')
plt.gcf().axes[0].tick_params(color='black')
plt.gcf().axes[1].tick_params(color='black')
plt.gcf().set_size_inches(10,6)

plt.show()

fprLR3, tprLR3, thesholdsLR3 = metrics.roc_curve(Ytest, y_pred3)

"""**Random Forest Classifier**"""

from sklearn.ensemble import RandomForestClassifier
rf_classifier = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)
rf_classifier.fit(Xtrain_tf, Ytrain)
y_pred4 = rf_classifier.predict(Xtest_tf)
print(confusion_matrix(Ytest, y_pred4))
print(classification_report(Ytest, y_pred4))
cm = confusion_matrix(Ytest, y_pred4)

matrix = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])

matrix.plot(cmap=plt.cm.Reds)

matrix.ax_.set_title('confusion Matrix Plot for Logistic Regression Classifier{L1}', color='black')
plt.xlabel('Predicted label', color='black')
plt.ylabel('True label', color='black')
plt.gcf().axes[0].tick_params(color='black')
plt.gcf().axes[1].tick_params(color='black')
plt.gcf().set_size_inches(10,6)

plt.show()

fprRF, tprRF, thresholdsRF = metrics.roc_curve(Ytest, y_pred4)

"""**Stochastic Gradient descent**"""

from sklearn.linear_model import SGDClassifier
sgd_classifier = SGDClassifier(loss='log_loss', penalty='l2',max_iter=10, random_state=0)
sgd_classifier.fit(Xtrain_tf, Ytrain)
y_pred5 = sgd_classifier.predict(Xtest_tf)

print(confusion_matrix(Ytest, y_pred5))
print(classification_report(Ytest, y_pred5))
cm = confusion_matrix(Ytest, y_pred5)

matrix = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])

matrix.plot(cmap=plt.cm.Reds)

matrix.ax_.set_title('confusion Matrix Plot for Logistic Regression Classifier{L1}', color='black')
plt.xlabel('Predicted label', color='black')
plt.ylabel('True label', color='black')
plt.gcf().axes[0].tick_params(color='black')
plt.gcf().axes[1].tick_params(color='black')
plt.gcf().set_size_inches(10,6)

plt.show()

fprSGR, tprSGR, thresholdsSGR = metrics.roc_curve(Ytest, y_pred5)

"""Random search(RS_CV)"""

from sklearn.model_selection import RandomizedSearchCV
from scipy import stats
svm_clf = svm.SVC(probability=True, random_state=1)
avc = make_scorer(accuracy_score)

rand_list = {"C":stats.uniform(2,10), # Corrected parameter name to 'C'
             "gamma": stats.uniform(0.1,1),
             'kernel': ['rbf']
             }
rand_search = RandomizedSearchCV(svm_clf,param_distributions=rand_list, n_iter=20,n_jobs=4,cv=3,random_state=2017,scoring=avc)
rand_search.fit(Xtrain_tf, Ytrain)
rand_search.cv_results_
rand_predictions = rand_search.predict(Xtest_tf)
print(confusion_matrix(Ytest, rand_predictions))
print(classification_report(Ytest, rand_predictions))

cm = confusion_matrix(Ytest, rand_predictions)

matrix = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])

matrix.plot(cmap=plt.cm.Reds)

matrix.ax_.set_title('confusion Matrix Plot for Random Search Classifier', color='black')
plt.xlabel('Predicted label', color='black')
plt.ylabel('True label', color='black')
plt.gcf().axes[0].tick_params(color='black')
plt.gcf().axes[1].tick_params(color='black')
plt.gcf().set_size_inches(10,6)

plt.show()

fprSVM_optimized, tprSVM_optimized, thresholdsSVM_optimized = metrics.roc_curve(Ytest, rand_predictions)

"""**ROC Curve**"""

from matplotlib import pyplot as plt
from sklearn.metrics import auc, RocCurveDisplay
plt.figure(1)
plt.figure(figsize=(8,6), dpi=300)
plt.plot([0, 1], [0, 1], 'k--')

auc_LR = auc(fprLR, tprLR)
auc_LR2 = auc(fprLR2, tprLR2)
auc_SVM = auc(fprLR3, tprLR3)
auc_RF = auc(fprRF, tprRF)
auc_SGR = auc(fprSGR, tprSGR)
auc_SVM_optimized = auc(fprSVM_optimized, tprSVM_optimized) # Corrected variable name

plt.plot(fprLR, tprLR, label='Logistic Regression (area={:.3f})'.format(auc_LR))
plt.plot(fprLR2, tprLR2, label='Logistic Regression L2 (area={:.3f})'.format(auc_LR2))
plt.plot(fprLR3, tprLR3, label='SVM (area={:.3f})'.format(auc_SVM))
plt.plot(fprRF, tprRF, label='Random Forest (area={:.3f})'.format(auc_RF))
plt.plot(fprSGR, tprSGR, label='Stochastic Gradient Descent (area={:.3f})'.format(auc_SGR))
plt.plot(fprSVM_optimized, tprSVM_optimized, label='Random search SVM (area={:.3f})'.format(auc_SVM_optimized)) # Corrected variable name

plt.legend(loc = 'lower right')
plt.show()

"""Model save"""

!pip install cloudpickle

import cloudpickle

with open('/content/drive/MyDrive/Colab Notebooks/Sentiment7.ipynb', 'wb')as f:
  cloudpickle.dump(rand_search, f)

with open('/content/drive/MyDrive/Colab Notebooks/Sentiment7.ipynb', 'rb')as f:
  rand_search = cloudpickle.load(f)

def predict_sentiment(input_sentence):
  words = tokenizer.bn_word_tokenizer(input_sentence)
  wordsExcludingPunctuation = [word for word in words if word not in punctuation_marks]
  wordsExcludingStopwords = [word for word in wordsExcludingPunctuation if word not in bangla_stopwords]
  transformed_input = tfidf.transform([' '. join(wordsExcludingStopwords)])

  prediction = rand_search.predict(transformed_input)
  print(f"predicted sentiment: {'Positive' if prediction[0] == 1 else 'Negative'}")

input_sentence = "এই পণ্যটি কাজ করছে না ।"
predict_sentiment(input_sentence)